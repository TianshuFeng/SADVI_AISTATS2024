{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b022fbac-aad1-42a6-acce-54bc1f46683d",
   "metadata": {},
   "source": [
    "# Revised two toy examples for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4970e2-f7db-4cf4-ad03-eac9caf01a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bvae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ace1ca-31fa-4235-b843-ad61a1f5f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% # prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.interpolate import BSpline\n",
    "import numpy as np\n",
    "from torch.distributions import MultivariateNormal, Normal, RelaxedOneHotCategorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch.distributions as td\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9f45a-617b-4321-ac43-74ec43882856",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcae1d92-6ad1-400f-806d-ee5a5a0704fd",
   "metadata": {},
   "source": [
    "## Gamma distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae244cab-4963-4798-b374-aeb95dd4fa07",
   "metadata": {},
   "source": [
    "### Model and data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16442345-d170-4b05-80c7-a238f629de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceGammaBVAE(BVAE):\n",
    "    def __init__(self, input_dim: int, hidden_dim: list, z_dim,\n",
    "                 k: int = 3, t: list = [0.25, 0.5, 0.75], n_mcmc = 10000,\n",
    "                 device = 'cpu', mnist_transform = True):\n",
    "        super(InferenceGammaBVAE, self).__init__(input_dim, hidden_dim, z_dim, \n",
    "                                         k, t, n_mcmc,\n",
    "                                         device, mnist_transform)\n",
    "        \n",
    "    def forward(self, x, temperature = 0.1):\n",
    "        \n",
    "        latent_vars = self.encoder(x)  # T X batch X z_dim X (n_basis + 2)\n",
    "        \n",
    "        mu = torch.abs(latent_vars[..., 0])\n",
    "        log_var = latent_vars[..., 1]  # T X batch X z_dim\n",
    "        z_std = log_var.mul(0.5).exp_()\n",
    "        \n",
    "        latent_vars = latent_vars[..., 2:]\n",
    "        \n",
    "        coef_spl, weights = self.latent_scaling(latent_vars=latent_vars)\n",
    "        z_sample_approx, pdf_approx = self.approx_sampling(coef_spl=coef_spl, \n",
    "                                                            temperature = temperature)  # both are T * batch * z_dim        \n",
    "        z_sample_approx = z_sample_approx * z_std + mu\n",
    "        pdf_approx = pdf_approx\n",
    "        log_pdf_approx = torch.log(pdf_approx) - torch.log(z_std)\n",
    "        \n",
    "        return coef_spl, weights, z_sample_approx, log_pdf_approx, z_std\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_function(x, z_approx, log_pdf_approx, z_std, prior, beta = 0.05):\n",
    "        \n",
    "        z_dim = z_approx.shape[-1]\n",
    "        device = z_approx.device\n",
    "        # IWAE now\n",
    "                \n",
    "        # Find p(x|z)\n",
    "        px_Gz = td.Exponential(z_approx).log_prob(x)  # T X batch_size X x_dim\n",
    "        log_PxGz = torch.sum(px_Gz, -1)  # T X batch_size\n",
    "        # Find p(z)\n",
    "        log_Pz = prior.log_prob(z_approx)  \n",
    "        log_Pz = torch.sum(log_Pz, -1)   # T X Batch\n",
    "        # Find q(z|x)\n",
    "        log_QzGx = log_pdf_approx.sum(-1)  # T X Batch\n",
    "        log_loss = log_PxGz + (log_Pz - log_QzGx)*beta  \n",
    "        \n",
    "        return -torch.mean(torch.logsumexp(log_loss, 0))\n",
    "    \n",
    "    def calc_loss(self, x, z, T = 1, prior = None, beta = 0.05, temperature = 0.1,\n",
    "                  coef_entropy_penalty = 0.5, coef_indi_penalty = 0, coef_spline_penalty = 0):\n",
    "        \n",
    "        # Set T=1 to use ELBO, T>1 to use IWAE\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.expand(T, *x.shape).to(self.device)\n",
    "        z = z.expand(T, *z.shape).to(self.device)\n",
    "        \n",
    "        coef_spl, weights, z_approx, log_pdf_approx, z_std = self.forward(x,temperature)\n",
    "        if prior is None:\n",
    "            prior =  MultivariateNormal(loc = torch.zeros(self.z_dim, \n",
    "                                                            device = self.device),\n",
    "                                        covariance_matrix=100. * torch.eye(self.z_dim, \n",
    "                                                                    device = self.device))\n",
    "        \n",
    "        loss = self.loss_function(x, z_approx, \n",
    "                                  log_pdf_approx, z_std = z_std, prior = prior, \n",
    "                                  beta = beta)\n",
    "        \n",
    "        entropy_penalty, indi_penalty = self.mixture_penalties(coef_spl)\n",
    "        entropy_penalty = torch.mean(torch.logsumexp(entropy_penalty, 0))\n",
    "\n",
    "        spline_penalty = (torch.matmul(weights.float(), self.spline_penalty_matrix.float()) * weights.float()).sum(-1)  # T X batch_size X z_dim\n",
    "        spline_penalty = torch.mean(spline_penalty)\n",
    "        \n",
    "        return loss + coef_entropy_penalty * entropy_penalty + coef_spline_penalty * spline_penalty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74378a7e-d033-4a34-a669-88863dfae2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "z_toy_dist = td.Gamma(torch.tensor(2., device = DEVICE), \n",
    "                      torch.tensor(2., device = DEVICE))\n",
    "z_toy = z_toy_dist.sample([1024])\n",
    "x_toy_dist = td.Exponential(z_toy)\n",
    "x_toy = x_toy_dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee80f20-a918-4aff-9032-2d3c4b816de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_toy.unsqueeze(-1), z_toy)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69f57317-6436-4004-ba73-3059bff11d24",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63167e52-48a2-46e9-afc6-be350a0eb549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "bvae_toy = InferenceGammaBVAE(1, hidden_dim=[20, 20], z_dim=1, t = list(np.linspace(0.1, 0.9, 6)),\n",
    "                device = DEVICE, mnist_transform = False)\n",
    "optimizer = optim.Adam(bvae_toy.parameters())\n",
    "prior = z_toy_dist\n",
    "\n",
    "tepoch = tqdm.tqdm(range(75))\n",
    "for epoch in tepoch:\n",
    "    torch.manual_seed(epoch)\n",
    "    tloader = tqdm.tqdm(train_loader, disable = True)\n",
    "    for batch_idx, (x, z) in enumerate(tloader):\n",
    "        torch.manual_seed(batch_idx*epoch)\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        loss = bvae_toy.calc_loss(x, z, 10, prior = prior, beta = 0.7,\n",
    "                                 coef_entropy_penalty = 0.5,\n",
    "                                 coef_spline_penalty = 0.5e-9 ,\n",
    "                                 temperature = float(0.05 + np.exp(-epoch/4)))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            tepoch.set_postfix({\"Epoch\": epoch, \"Loss\": loss.item() / len(x)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e84e45-1694-4ea1-9957-812c9cef4270",
   "metadata": {},
   "source": [
    "### Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e41e8-5e02-44a9-8c31-2c7e0ff73c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvae_toy.eval()\n",
    "x = torch.tensor([.5], device = DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "latent_vars = bvae_toy.encoder(x)  # T X batch X z_dim X n_basis\n",
    "\n",
    "mu = torch.abs(latent_vars[..., 0])\n",
    "log_var = latent_vars[..., 1]  # batch X z_dim\n",
    "z_std = log_var.mul(0.5).exp_()\n",
    "\n",
    "latent_vars = latent_vars[..., 2:]\n",
    "coef_spl, weights = bvae_toy.latent_scaling(latent_vars=latent_vars)\n",
    "z_sample_approx, pdf_approx = bvae_toy.approx_sampling(coef_spl=coef_spl)  # both are batch * z_dim\n",
    "z_sample_approx = z_sample_approx * z_std + mu\n",
    "log_pdf_approx = torch.log(pdf_approx) - torch.log(z_std) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bvae_toy.loss_function(x, z_sample_approx, \n",
    "                                  log_pdf_approx, z_std = z_std, prior = z_toy_dist, \n",
    "                                  beta = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0500481-d902-4d83-954c-55b646c26159",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gamma = td.Gamma(2+1, 2 + .5)\n",
    "xx = np.linspace(0.01,5., 1000)\n",
    "xx_bspl = np.linspace(0.01,0.95, 1000)\n",
    "pdf = res_gamma.log_prob(xx)\n",
    "wgt = weights[0,0,0].detach().cpu().numpy()\n",
    "spl = BSpline(bvae_toy.t, wgt, \n",
    "                  bvae_toy.k, extrapolate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5863c1-42ef-429e-a0f0-f76804ce231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2))\n",
    "\n",
    "plt.plot(xx, np.exp(pdf.numpy()), label = 'Analytical')\n",
    "plt.plot(xx_bspl*z_std.item() + mu.item(), \n",
    "         spl(xx_bspl)/z_std.item()/spl.integrate(0,1)*1.0, \n",
    "         label = 'Approximated')\n",
    "for basis_idx in range(len(bvae_toy.basis_func)):\n",
    "    if basis_idx == 4:\n",
    "        l_wd = 1\n",
    "        plt.plot(xx_bspl*z_std.item() + mu.item(), \n",
    "             bvae_toy.basis_func[basis_idx](xx_bspl) * \n",
    "              wgt[basis_idx]/z_std.item()/spl.integrate(0,1), \n",
    "             alpha = 0.5, linewidth = l_wd, c = 'C2',\n",
    "                label = 'Weighted basis')\n",
    "    else:\n",
    "        l_wd = 1\n",
    "    plt.plot(xx_bspl*z_std.item() + mu.item(), \n",
    "             bvae_toy.basis_func[basis_idx](xx_bspl) * \n",
    "              wgt[basis_idx]/z_std.item()/spl.integrate(0,1), \n",
    "             alpha = 0.5, linewidth = l_wd, c = 'C2')\n",
    "\n",
    "plt.xlabel(r\"$z$\")\n",
    "plt.ylabel(r\"$q(z| \\mathbf{x})$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c1c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8df14c5-bdec-463c-b3b3-76f01cfe2788",
   "metadata": {},
   "source": [
    "## Gaussian mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67bcdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceBVAE(BVAE):\n",
    "    def __init__(self, input_dim: int, hidden_dim: list, z_dim,\n",
    "                 k: int = 3, t: list = [0.25, 0.5, 0.75], n_mcmc = 10000,\n",
    "                 device = 'cpu', mnist_transform = True):\n",
    "        super(InferenceBVAE, self).__init__(input_dim, hidden_dim, z_dim, \n",
    "                                         k, t, n_mcmc,\n",
    "                                         device, mnist_transform)\n",
    "    \n",
    "    def forward(self, x, temperature = 0.1):\n",
    "        \n",
    "        latent_vars = self.encoder(x)  # T X batch X z_dim X (n_basis + 2)\n",
    "        mu = latent_vars[..., 0]\n",
    "        log_var = latent_vars[..., 1]  # T X batch X z_dim\n",
    "        z_std = log_var.mul(0.5).exp_()\n",
    "        latent_vars = latent_vars[..., 2:]\n",
    "        \n",
    "        coef_spl, weights = self.latent_scaling(latent_vars=latent_vars)\n",
    "        z_sample_approx, pdf_approx = self.approx_sampling(coef_spl=coef_spl, \n",
    "                                                            temperature = temperature)  # both are T * batch * z_dim\n",
    "        z_sample_approx = z_sample_approx * z_std + mu\n",
    "        # Transform because of the standard deviation\n",
    "        pdf_approx = pdf_approx\n",
    "        log_pdf_approx = torch.log(pdf_approx) - torch.log(z_std) * 1\n",
    "        \n",
    "        return coef_spl, weights, z_sample_approx, log_pdf_approx, z_std\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_function(x, z_approx, log_pdf_approx, z_std, prior, beta = 0.05):\n",
    "        \n",
    "        z_dim = z_approx.shape[-1]\n",
    "        device = z_approx.device\n",
    "        # IWAE now\n",
    "                \n",
    "        # Find p(x|z)\n",
    "        px_Gz = Normal(loc= z_approx, scale=np.sqrt(1)).log_prob(x)  # T X batch_size X x_dim\n",
    "        log_PxGz = torch.sum(px_Gz, -1)  # T X batch_size\n",
    "        # Find p(z)\n",
    "        log_Pz = prior.log_prob(z_approx)  \n",
    "        log_Pz = torch.sum(log_Pz, -1)   # T X Batch\n",
    "        # Find q(z|x)\n",
    "        log_QzGx = log_pdf_approx.sum(-1)  # T X Batch\n",
    "        log_loss = log_PxGz + (log_Pz - log_QzGx)*beta   # log_PxGz + \n",
    "        \n",
    "        return -torch.mean(torch.logsumexp(log_loss, 0))\n",
    "    \n",
    "    def calc_loss(self, x, z, T = 1, prior = None, beta = 0.05, temperature = 0.1,\n",
    "                  coef_entropy_penalty = 0.5, coef_indi_penalty = 0,\n",
    "                  coef_spline_penalty = 0):\n",
    "        \n",
    "        # Set T=1 to use ELBO, T>1 to use IWAE\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.expand(T, *x.shape).to(self.device)\n",
    "        z = z.expand(T, *z.shape).to(self.device)\n",
    "        coef_spl, weights, z_approx, log_pdf_approx, z_std = self.forward(x, temperature)\n",
    "        if prior is None:\n",
    "            prior =  MultivariateNormal(loc = torch.zeros(self.z_dim, \n",
    "                                                            device = self.device),\n",
    "                                        covariance_matrix=100. * torch.eye(self.z_dim, \n",
    "                                                                    device = self.device))\n",
    "        \n",
    "        loss = self.loss_function(x, z_approx, \n",
    "                                  log_pdf_approx, z_std = z_std, prior = prior, \n",
    "                                  beta = beta)\n",
    "        \n",
    "        entropy_penalty, indi_penalty = self.mixture_penalties(coef_spl)\n",
    "        entropy_penalty = torch.mean(torch.logsumexp(entropy_penalty, 0))\n",
    "        \n",
    "        spline_penalty = (torch.matmul(weights.float(), self.spline_penalty_matrix.float()) * weights.float()).sum(-1)  # T X batch_size X z_dim\n",
    "        spline_penalty = torch.mean(spline_penalty)\n",
    "        \n",
    "        return loss + coef_entropy_penalty * entropy_penalty + coef_spline_penalty * spline_penalty # + coef_indi_penalty * indi_penalty\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f073c149-fbf2-4d05-9a04-42e592350ce5",
   "metadata": {},
   "source": [
    "### Model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3467b44-7b24-4add-84e5-4525858a879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "mix = td.Categorical(torch.ones(2,).to(DEVICE))\n",
    "comp = td.Normal(torch.tensor([0.5, -0.5], device = DEVICE), \n",
    "                torch.tensor([np.sqrt(.1), np.sqrt(.1)], device = DEVICE))\n",
    "z_toy_dist = td.MixtureSameFamily(mix, comp)\n",
    "\n",
    "z_toy = z_toy_dist.sample([2048])\n",
    "x_toy_dist = td.Normal(z_toy, 1.)\n",
    "x_toy = x_toy_dist.sample()\n",
    "\n",
    "train_dataset = TensorDataset(x_toy.unsqueeze(-1), z_toy)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd9f03b9-5247-47d2-9723-bee1d1c4cd82",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a75b41-359d-4f9a-9dab-ff3cd9f691b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "bvae_toy = InferenceBVAE(1, hidden_dim=[20, 20], z_dim=1, t = list(np.linspace(0.1, 0.9, 9)),\n",
    "                device = DEVICE, mnist_transform = False)\n",
    "\n",
    "optimizer = optim.Adam(bvae_toy.parameters())\n",
    "\n",
    "prior = z_toy_dist\n",
    "\n",
    "tepoch = tqdm.tqdm(range(50))\n",
    "for epoch in tepoch:\n",
    "    torch.manual_seed(epoch)\n",
    "    tloader = tqdm.tqdm(train_loader, disable = True)\n",
    "    for batch_idx, (x, z) in enumerate(tloader):\n",
    "\n",
    "        torch.manual_seed(batch_idx*epoch)\n",
    "\n",
    "        train_loss = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = bvae_toy.calc_loss(x, z, 10, prior = prior, beta = 0.65,\n",
    "                                 coef_entropy_penalty = .5,\n",
    "                                 coef_spline_penalty = 1e-15 ,\n",
    "                                 temperature = float(0.05 + np.exp(-epoch/8)))\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            #     epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            #     100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "            tepoch.set_postfix({\"Epoch\": epoch, \"Loss\": loss.item() / len(x)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92ccbb82-3eb6-4822-a877-ea50388684b8",
   "metadata": {},
   "source": [
    "### Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a912212-f4b6-4d3c-8c92-24befd027b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bvae_toy.eval()\n",
    "\n",
    "x = torch.tensor([0.5], device = DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "latent_vars = bvae_toy.encoder(x)  # T X batch X z_dim X n_basis\n",
    "# expected loss version\n",
    "mu = latent_vars[..., 0]\n",
    "log_var = latent_vars[..., 1]  # batch X z_dim\n",
    "std_dec = log_var.mul(0.5).exp_()\n",
    "latent_vars = latent_vars[..., 2:]\n",
    "\n",
    "coef_spl, weights = bvae_toy.latent_scaling(latent_vars=latent_vars)\n",
    "z_sample_approx, pdf_approx = bvae_toy.approx_sampling(coef_spl=coef_spl)  # both are batch * z_dim\n",
    "z_sample_approx = z_sample_approx * std_dec + mu\n",
    "wgt = weights[0,0,0].detach().cpu().numpy()\n",
    "spl = BSpline(bvae_toy.t, wgt, \n",
    "                  bvae_toy.k, extrapolate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4006a1b-5572-456e-8b9a-d3b090127598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_posterior_gm(z, x, sigma_prior, sigma_likelihood):\n",
    "    res = 1/(4 * np.pi * sigma_likelihood * sigma_prior) * np.exp( - (( x - z )**2)/(2 * (sigma_likelihood**2)) ) * \\\n",
    "        ( np.exp(-((z - 0.5)**2) / (2 * sigma_prior**2)) + np.exp(-((z + 0.5)**2) / (2 * sigma_prior**2)) )\n",
    "    return res\n",
    "xx_pdf = np.linspace(-8, 8, 10000)\n",
    "pdf = true_posterior_gm(xx_pdf, .5, np.sqrt(.1), np.sqrt(1))\n",
    "\n",
    "true_pdf_integral = np.sum(pdf)/10000*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e8fdd-460e-443a-8984-d501aed2ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.7,2))\n",
    "\n",
    "xx = np.linspace(0, 1, 100)\n",
    "spl = BSpline(bvae_toy.t, wgt, \n",
    "                  bvae_toy.k, extrapolate=False)\n",
    "\n",
    "plt.plot(xx*std_dec.item() + mu.item(), \n",
    "         spl(xx)/std_dec.item()/spl.integrate(0,1),\n",
    "         label = 'Approximated')\n",
    "\n",
    "xx_pdf = np.linspace(-1.2, 1.2, 1000)\n",
    "pdf = true_posterior_gm(xx_pdf, .5, np.sqrt(.1), np.sqrt(1))\n",
    "plt.plot(xx_pdf, pdf/true_pdf_integral, label = 'Analytical')\n",
    "\n",
    "for basis_idx in range(len(bvae_toy.basis_func)):\n",
    "    if basis_idx == 4:\n",
    "        l_wd = 1\n",
    "        plt.plot(xx*std_dec.item() + mu.item(), \n",
    "                bvae_toy.basis_func[basis_idx](xx) * \n",
    "                wgt[basis_idx] /std_dec.item()/spl.integrate(0,1), \n",
    "                alpha = 0.45, linewidth = l_wd, c = 'C2',\n",
    "                    label = 'Weighted basis')\n",
    "    else:\n",
    "        l_wd = 1\n",
    "        plt.plot(xx*std_dec.item() + mu.item(), \n",
    "                bvae_toy.basis_func[basis_idx](xx) * \n",
    "                wgt[basis_idx] /std_dec.item()/spl.integrate(0,1), \n",
    "                alpha = 0.45, linewidth = l_wd, c = 'C2')\n",
    "\n",
    "plt.xlabel(r\"$z$\")\n",
    "plt.ylabel(r\"$q(z| \\mathbf{x})$\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
