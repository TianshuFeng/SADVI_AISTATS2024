{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441ff40-05a8-4fc7-ae4d-bfffff916c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bvae import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7e6e7-14d4-4229-b519-6883bb1bc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% # prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.interpolate import BSpline\n",
    "import numpy as np\n",
    "from torch.distributions import MultivariateNormal, Normal, RelaxedOneHotCategorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdea418-4ca1-47c7-a501-db97bc660abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1f5d2-fe08-4c40-abc2-e0cafca4d35b",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de652901-66ee-4d7d-b180-36fe6f4ec151",
   "metadata": {},
   "outputs": [],
   "source": [
    "minst_dir = './'\n",
    "\n",
    "train_dataset = datasets.MNIST(root=minst_dir,\n",
    "                               train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root=minst_dir, \n",
    "                               train=False, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5bb49-f220-4893-b4c8-b6701a9ebee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650a52b-542c-4d55-bebc-41e88236f988",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a78e69-8804-4b89-8759-aa2e3c43395e",
   "metadata": {},
   "source": [
    "### BVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba463803-88c2-4415-96df-9205564a41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineBVAE(BVAE):\n",
    "    def __init__(self, input_dim: int, hidden_dim: list, z_dim, n_class, \n",
    "                 k: int = 3, t: list = [0.25, 0.5, 0.75], n_mcmc = 10000,\n",
    "                 device = 'cpu', mnist_transform = True, *args, **kwargs):\n",
    "        super(AffineBVAE, self).__init__(input_dim, hidden_dim, z_dim, \n",
    "                                         k, t, n_mcmc,\n",
    "                                         device, mnist_transform)\n",
    "        \n",
    "        self.decoder_affine = nn.Linear(z_dim, n_class)\n",
    "        \n",
    "        self.to(device)\n",
    "    \n",
    "    def latent_scaling(self, latent_vars):\n",
    "        \n",
    "        # With sigmoid\n",
    "        latent_vars = latent_vars/(.5*torch.std(latent_vars, dim = -1, \n",
    "                                             keepdim = True, unbiased = True)+0.01)\n",
    "        coef_spl = F.softmax(latent_vars, dim = -1)  # T * batch * z_dim * n_basis   # between 0 and 1 for multinomial distribution\n",
    "        basis_integral = torch.tensor(self.basis_integral.reshape(1,1,1,-1), device = self.device) # 1 * 1 * 1 * n_basis\n",
    "        weights = coef_spl/basis_integral # T * batch * z_dim * n_basis  # For constructing the bpline approximation\n",
    "        \n",
    "        return coef_spl, weights\n",
    "    \n",
    "    def forward(self, x, temperature = 0.1):\n",
    "        \n",
    "        latent_vars = self.encoder(x)  # T X batch X z_dim X (n_basis + 2)\n",
    "        mu = latent_vars[..., 0]\n",
    "        log_var = latent_vars[..., 1]  # T X batch X z_dim\n",
    "        z_std = log_var.mul(0.5).exp_()\n",
    "        latent_vars = latent_vars[..., 2:]\n",
    "        \n",
    "        coef_spl, weights = self.latent_scaling(latent_vars=latent_vars)\n",
    "        try:\n",
    "            z_sample_approx, pdf_approx = self.approx_sampling(coef_spl=coef_spl, \n",
    "                                                               temperature = temperature)  # both are T * batch * z_dim\n",
    "        except:\n",
    "            print(coef_spl)\n",
    "            raise\n",
    "        z_sample_approx = z_sample_approx * z_std + mu\n",
    "        log_pdf_approx = torch.log(pdf_approx) - 1.*torch.log(z_std)\n",
    "        recon_mean = self.decoder_affine(z_sample_approx)\n",
    "        logits = F.softmax(recon_mean, -1)\n",
    "\n",
    "        return logits, coef_spl, weights, z_sample_approx, log_pdf_approx, z_std\n",
    "    \n",
    "    def predict(self, x, n_samples = 5):\n",
    "        \n",
    "        self.eval()\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.expand(n_samples, *x.shape).to(self.device)\n",
    "        logits, coef_spl, weights, \\\n",
    "            z_sample_approx, log_pdf_approx, z_std = self.forward(x)\n",
    "        pred_index = logits.max(2)[1]\n",
    "        pred_index_mode = pred_index.mode(0)[0]\n",
    "        \n",
    "        return logits.mean(0).max(-1)[1].cpu() # pred_index_mode\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(logits, y, z, log_pdf_approx, z_std, beta = 1):\n",
    "        \n",
    "        z_dim = z.shape[-1]\n",
    "        device = z.device\n",
    "        # IWAE now\n",
    "        \n",
    "        prior = MultivariateNormal(loc = torch.zeros(z_dim, \n",
    "                                                     device = device),\n",
    "                                   scale_tril = 1. * torch.eye(z_dim, \n",
    "                                                                 device = device))\n",
    "        # Find p(y|z)\n",
    "        ori_y_shape = y.shape\n",
    "        class_loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), \n",
    "                                     y.reshape(-1), reduction = 'none').div(np.log(2)).view(*ori_y_shape)\n",
    "        # Find p(z)\n",
    "        log_Pz = prior.log_prob(z)  \n",
    "        # Find q(z|x)\n",
    "        log_QzGx = log_pdf_approx.sum(-1)  # T X Batch\n",
    "        log_loss = -class_loss + beta*(log_Pz - log_QzGx)  \n",
    "        \n",
    "        return -torch.mean(torch.logsumexp(log_loss, 0)) \n",
    "    \n",
    "    def calc_loss(self, x, y, T = 1, beta = 0.05, temperature = 0.1,\n",
    "                  coef_entropy_penalty = 5, coef_indi_penalty = 0,\n",
    "                  coef_spline_penalty = 0):\n",
    "        \n",
    "        # Set T=1 to use ELBO, T>1 to use IWAE\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.expand(T, *x.shape).to(self.device)\n",
    "        y = y.expand(T, *y.shape).to(self.device)\n",
    "        \n",
    "        logits, coef_spl, weights, \\\n",
    "            z_sample_approx, log_pdf_approx, z_std = self.forward(x, \n",
    "                                                              temperature = temperature)\n",
    "        loss = self.loss_function(logits, y, z_sample_approx, \n",
    "                                  log_pdf_approx, z_std = z_std,beta = beta)\n",
    "        entropy_penalty, indi_penalty = self.mixture_penalties(coef_spl)\n",
    "        entropy_penalty = torch.mean(torch.logsumexp(entropy_penalty, 0))\n",
    "        indi_penalty = torch.mean(torch.logsumexp(indi_penalty, 0))\n",
    "        # Use weights\n",
    "        spline_penalty = (torch.matmul(weights.float(), self.spline_penalty_matrix.float()) * weights.float()).sum(-1)  # T X batch_size X z_dim\n",
    "        spline_penalty = torch.mean(spline_penalty)\n",
    "        \n",
    "        return loss + coef_entropy_penalty * entropy_penalty + coef_indi_penalty * indi_penalty + coef_spline_penalty * spline_penalty\n",
    "    \n",
    "    def train_model(self, train_loader, epoch, optimizer = None,\n",
    "                    T = 1, coef_entropy_penalty = 10, coef_spline_penalty = 10, \n",
    "                    beta = 0.001,\n",
    "                    temperature = 0.1, \n",
    "                    center_only = True, tqdm_disable = False, *args, **kwargs):\n",
    "        self.train()\n",
    "        torch.manual_seed(epoch)\n",
    "        \n",
    "        if optimizer is None:\n",
    "            optimizer = optim.Adam(self.parameters())\n",
    "        \n",
    "        train_loss = 0\n",
    "        tloader = tqdm.tqdm(train_loader, disable = tqdm_disable)\n",
    "        \n",
    "        for batch_idx, (data, y) in enumerate(tloader):\n",
    "            \n",
    "            if self.mnist_transform:\n",
    "                if center_only:\n",
    "                    data[..., :13] = 0\n",
    "                    data[..., -14:] = 0\n",
    "                data = data.to(self.device).view(-1, 784)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.calc_loss(data, y, T = T, \n",
    "                                  coef_entropy_penalty = coef_entropy_penalty, \n",
    "                                  coef_spline_penalty = coef_spline_penalty,\n",
    "                                  coef_indi_penalty = 0, beta = beta,\n",
    "                                 temperature = temperature)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                tloader.set_postfix({\"Epoch\": epoch, \"Loss\": loss.item() / len(data)})\n",
    "                        \n",
    "        return train_loss / len(train_loader.dataset) # Average loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219ba46-8fad-4a6a-bd87-fb28cd0934a2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031ce7d-1909-4ee1-a748-1f191fcedeaf",
   "metadata": {},
   "source": [
    "### BVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd6de7-3eec-45d0-8e7d-ca978011fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "(data, y) = next(iter(test_loader))\n",
    "\n",
    "data_center = data\n",
    "data_center[..., :13] = 0\n",
    "data_center[..., -14:] = 0\n",
    "data_center = data_center.view(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36d213-1314-4559-b745-55e3e4c8de4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "bvae = AffineBVAE(784, hidden_dim=[512, 256], z_dim=4, n_class = 10,  device = DEVICE)\n",
    "optimizer = optim.Adam(bvae.parameters())\n",
    "\n",
    "lr = 0.001\n",
    "for epoch in range(0, 100):\n",
    "    bvae.train()\n",
    "    temperature = float(1-epoch*0.095*10/7 if epoch<7 else 0.05) #  float(0.05 + np.exp(-epoch/4))\n",
    "    \n",
    "    optimizer = optim.Adam(bvae.parameters(), lr = lr)\n",
    "    bvae.train_model(epoch = epoch, train_loader = train_loader, \n",
    "                     T=10, optimizer = optimizer, beta = 0.001,\n",
    "                     center_only = True, coef_spline_penalty = .00005,\n",
    "                    coef_entropy_penalty = .25,\n",
    "                    temperature = temperature)\n",
    "    # bvae.test_model(test_loader)\n",
    "    pred_ind = bvae.predict(data_center.to(DEVICE).view(-1, 784), n_samples = 100)\n",
    "    print(np.mean(pred_ind.cpu().numpy() == y.numpy()))\n",
    "    \n",
    "    lr = lr * 0.95\n",
    "bvae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0160d42-f392-4dd9-a4b2-7f128a8e14e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
